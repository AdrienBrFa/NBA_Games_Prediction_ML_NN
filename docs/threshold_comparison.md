# Threshold Optimization Strategy Comparison

**Generated:** 2025-12-12 02:16:59

This report compares model performance across different threshold optimization strategies:
- **F1-optimized**: Threshold selected to maximize F1 score on validation set (default)
- **Accuracy-optimized**: Threshold selected to maximize accuracy on validation set

**Note:** All models use the same trained weights. Only the decision threshold differs.

---

## Stage A1 - Historical Features Only

### Results Comparison

| Threshold Metric | Optimal Threshold | Test Accuracy | Test F1 | Test AUC | Test Log Loss |
|-----------------|-------------------|---------------|---------|----------|---------------|
| **accuracy** | 0.460 | 0.5867 | 0.6942 | 0.5959 | 0.6803 |
| **f1** | 0.360 | 0.5922 | 0.7106 | 0.6003 | 0.6785 |


### Confusion Matrices (Test Set)

#### ACCURACY

```
             Predicted
             0      1
Actual  0  |  593  1547
        1  |  416  2228
```

#### F1

```
             Predicted
             0      1
Actual  0  |  150  1990
        1  |   90  2554
```

### Archive Information

- **accuracy**: `run_20251212_020719_threshold-accuracy` (trained: 2025-12-12T02:07:13.236708)
- **f1**: `run_20251212_020547_threshold-f1` (trained: 2025-12-12T02:05:39.959202)

---

## Stage B1 Intermediate - Selected Rolling Metrics

### Results Comparison

| Threshold Metric | Optimal Threshold | Test Accuracy | Test F1 | Test AUC | Test Log Loss |
|-----------------|-------------------|---------------|---------|----------|---------------|
| **accuracy** | 0.430 | 0.6233 | 0.7045 | 0.6594 | 0.6501 |
| **f1** | 0.380 | 0.6220 | 0.7176 | 0.6590 | 0.6538 |


### Confusion Matrices (Test Set)

#### ACCURACY

```
             Predicted
             0      1
Actual  0  |  773  1365
        1  |  460  2175
```

#### F1

```
             Predicted
             0      1
Actual  0  |  386  1752
        1  |  180  2455
```

### Archive Information

- **accuracy**: `run_20251212_021116_threshold-accuracy` (trained: 2025-12-12T02:11:10.856041)
- **f1**: `run_20251212_020921_threshold-f1` (trained: 2025-12-12T02:09:15.151797)

---

## Stage B1 Full - Complete Feature Set

### Results Comparison

| Threshold Metric | Optimal Threshold | Test Accuracy | Test F1 | Test AUC | Test Log Loss |
|-----------------|-------------------|---------------|---------|----------|---------------|
| **accuracy** | 0.450 | 0.6256 | 0.6957 | 0.6701 | 0.6456 |
| **f1** | 0.380 | 0.6317 | 0.7200 | 0.6710 | 0.6431 |


### Confusion Matrices (Test Set)

#### ACCURACY

```
             Predicted
             0      1
Actual  0  |  990  1148
        1  |  617  2018
```

#### F1

```
             Predicted
             0      1
Actual  0  |  497  1641
        1  |  230  2405
```

### Archive Information

- **accuracy**: `run_20251212_021609_threshold-accuracy` (trained: 2025-12-12T02:16:04.060327)
- **f1**: `run_20251212_021346_threshold-f1` (trained: 2025-12-12T02:13:40.715873)

---

## Key Findings

### Metric Differences (Accuracy-optimized vs F1-optimized)

Positive values indicate that accuracy-optimized threshold performed better.

| Stage | Δ Accuracy | Δ F1 Score | Δ AUC | Δ Log Loss | Threshold Shift |
|-------|-----------|-----------|-------|-----------|----------------|
| Stage A1 | -0.0054 | -0.0164 | -0.0044 | +0.0018 | +0.100 |
| Stage B1-Int | +0.0013 | -0.0132 | +0.0004 | -0.0036 | +0.050 |
| Stage B1-Full | -0.0061 | -0.0242 | -0.0009 | +0.0025 | +0.070 |


## Interpretation Guide

### Threshold Selection
- **Lower thresholds** (< 0.5): Model predicts class 1 more frequently
- **Higher thresholds** (> 0.5): Model is more conservative, requires higher confidence
- **F1-optimized**: Balances precision and recall
- **Accuracy-optimized**: Maximizes overall correct predictions

### When to Use Each Strategy
- **F1 optimization**: When false positives and false negatives have similar costs
- **Accuracy optimization**: When overall correctness matters most
- **Custom threshold**: Set manually based on domain requirements and cost analysis

### AUC vs Threshold
- **AUC** is threshold-independent (same for all strategies with same model weights)
- Small AUC differences indicate numerical/random variation, not meaningful differences

---

*This report was automatically generated by `compare_thresholds.py`*
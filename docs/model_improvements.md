# Am√©liorations du Mod√®le MLP - NBA Game Predictions

## üìä Analyse des R√©sultats Initiaux

Les r√©sultats initiaux montraient des signes de **surapprentissage** :
- **Accuracy Train**: 68.3% vs **Test**: 57.7%
- **AUC Train**: 0.681 vs **Test**: 0.575
- Le mod√®le s'entra√Ænait pendant 13 epochs avec patience=10

## ‚úÖ Modifications Impl√©ment√©es

### 1. **R√©duction de la Patience (10 ‚Üí 5)**
```python
patience = 5  # Au lieu de 10
```
**Objectif** : Arr√™ter l'entra√Ænement plus t√¥t pour √©viter le surapprentissage.

### 2. **R√©gularisation L2**
```python
kernel_regularizer=regularizers.l2(0.001)  # Sur toutes les couches Dense
```
**Objectif** : P√©naliser les poids trop importants, favorisant un mod√®le plus g√©n√©ralisable.

**Force de r√©gularisation** : `l2_reg = 0.001` (l√©ger)

### 3. **Dropout Layers**
```python
layers.Dropout(0.3)  # 30% de dropout apr√®s chaque couche cach√©e
```
**Objectif** : D√©sactiver al√©atoirement 30% des neurones pendant l'entra√Ænement pour am√©liorer la g√©n√©ralisation.

### 4. **ReduceLROnPlateau**
```python
ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,        # Divise le learning rate par 2
    patience=3,        # Apr√®s 3 epochs sans am√©lioration
    min_lr=1e-6
)
```
**Objectif** : Ajuster dynamiquement le taux d'apprentissage pour une convergence plus fine.

### 5. **Optimisation du Seuil de D√©cision**
```python
optimal_threshold = find_optimal_threshold(y_val, y_pred_proba, method='f1')
```
**M√©thodes disponibles** :
- `'f1'` : Maximise le F1-score (balance pr√©cision/rappel) ‚úÖ **Par d√©faut**
- `'youden'` : Maximise l'indice de Youden (sensibilit√© + sp√©cificit√© - 1)
- `'balanced'` : Minimise la diff√©rence entre sensibilit√© et sp√©cificit√©

**Objectif** : Trouver le seuil optimal (au lieu de 0.5) bas√© sur le set de validation pour maximiser la performance.

## üìà Architecture Finale du Mod√®le

```
Input (n features)
    ‚Üì
Dense(64, relu) + L2(0.001)
    ‚Üì
Dropout(0.3)
    ‚Üì
Dense(32, relu) + L2(0.001)
    ‚Üì
Dropout(0.3)
    ‚Üì
Dense(1, sigmoid)
```

## üéØ Autres Propositions (Sans Changer de Mod√®le)

### A. **Augmentation de Donn√©es Temporelles**
- Cr√©er des features de moyennes mobiles sur 10/15 jours
- Ajouter des features d'√©cart-type pour capturer la variance des performances

### B. **Feature Engineering Avanc√©**
- Ratio home/away win rates
- Streak features (nombre de victoires/d√©faites cons√©cutives)
- Performance head-to-head entre √©quipes sp√©cifiques
- Features de "back-to-back" games (fatigue)

### C. **Ensembling L√©ger**
- Entra√Æner 3-5 mod√®les avec diff√©rentes seeds
- Faire la moyenne des pr√©dictions (bagging)

### D. **Ajuster l'Architecture**
- Tester diff√©rentes profondeurs : `[64, 64, 32]` ou `[128, 64, 32]`
- Exp√©rimenter avec BatchNormalization au lieu de/avec Dropout
- Tester diff√©rentes fonctions d'activation (LeakyReLU, ELU)

### E. **Class Weighting**
Si d√©s√©quilibre de classes (environ 60% home wins) :
```python
class_weight = {0: 1.5, 1: 1.0}  # Pond√©rer les away wins
```

### F. **Cross-Validation Temporelle**
- Impl√©menter une validation crois√©e respectant l'ordre chronologique
- Entra√Æner sur plusieurs splits temporels pour robustesse

## üöÄ Utilisation

Le pipeline met automatiquement en ≈ìuvre toutes les am√©liorations :

```bash
python run_pipeline.py
```

Le mod√®le affichera :
1. La configuration (L2, Dropout, Patience)
2. Le seuil optimal trouv√© sur le set de validation
3. Les performances avec seuil par d√©faut (0.5) ET seuil optimal
4. Les visualisations compl√®tes dans `outputs/plots/`

## üìä M√©triques √† Surveiller

- **F1 Score** : Balance entre pr√©cision et rappel
- **Gap Train-Test** : Indicateur de surapprentissage
- **AUC** : Performance ind√©pendante du seuil
- **Confusion Matrix** : Distribution des erreurs

## üîß Param√®tres Ajustables

Dans `scripts/train_model.py`, fonction `train_model()` :
```python
train_model(
    X_train, y_train, X_val, y_val,
    epochs=100,
    batch_size=64,
    patience=5,           # ‚Üê Ajustable
    l2_reg=0.001,        # ‚Üê Ajustable (0.0001 - 0.01)
    dropout_rate=0.3     # ‚Üê Ajustable (0.2 - 0.5)
)
```

## üìù Notes

- Les visualisations incluent maintenant les courbes de learning rate si ReduceLROnPlateau est actif
- Le seuil optimal est sauvegard√© dans `outputs/results.json`
- Les m√©triques incluent d√©sormais le F1-score pour chaque set
